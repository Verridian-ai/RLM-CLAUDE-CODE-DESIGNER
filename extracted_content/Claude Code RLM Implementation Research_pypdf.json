{
  "timestamp": "2026-01-05T05:13:41.860253",
  "extraction_metadata": {
    "page_count": 17,
    "metadata": {
      "/Title": "Claude Code RLM Implementation Research",
      "/Producer": "Skia/PDF m145 Google Docs Renderer"
    },
    "method": "pypdf"
  },
  "content": "\n--- PAGE 1 ---\nImplementing  the  'Cannot  Fail'  Recursive  \nLanguage\n \nModel\n \n(RLM)\n \nArchitecture\n \nwithin\n \nClaude\n \nCode:\n \nA\n \nFeasibility\n \nStudy\n \nand\n \nImplementation\n \nFramework\n Executive  Summary  \nThe  trajectory  of  Large  Language  Model  (LLM)  development  has  recently  encountered  a  \npersistent\n \nand\n \nnon-trivial\n \nbottleneck:\n \nthe\n \neffective\n \ncontext\n \nwindow.\n \nWhile\n \nfrontier\n \nmodels\n \nnow\n \nadvertise\n \ninput\n \ncapacities\n \nexceeding\n \none\n \nmillion\n \ntokens,\n \nrigorous\n \nempirical\n \nanalysis\n \ndemonstrates\n \na\n \nphenomenon\n \nknown\n \nas\n \n\"context\n \nrot,\"\n \nwhere\n \nreasoning\n \ncapabilities\n \ndegrade\n \nsignificantly\n \nas\n \ninformation\n \ndensity\n \nincreases\n \nand\n \nthe\n \nposition\n \nof\n \ncritical\n \ninformation\n \nshifts\n \ndeeper\n \ninto\n \nthe\n \nprompt\n \ncontext.\n1\n This  degradation  poses  a  fundamental  challenge  for  \nlong-horizon\n \ntasks\n \nsuch\n \nas\n \ndeep\n \nresearch,\n \ncodebase\n \nrefactoring,\n \nand\n \ncomplex\n \nlegal\n \nanalysis,\n \nwhere\n \nthe\n \nintegrity\n \nof\n \ninformation\n \nretrieval\n \nmust\n \nremain\n \nabsolute\n \nregardless\n \nof\n \nthe\n \ninput\n \nvolume.\n \nThe\n \nRecursive\n \nLanguage\n \nModel\n \n(RLM)\n \nframework,\n \nas\n \nproposed\n \nby\n \nZhang\n \net\n \nal.,\n \noffers\n \na\n \nparadigm\n \nshift\n \nto\n \naddress\n \nthis\n \nlimitation.\n \nBy\n \ntreating\n \nthe\n \nprompt\n \nnot\n \nas\n \nan\n \nimmediate,\n \nholistic\n \ninput\n \nto\n \nthe\n \ntransformer\n \nbut\n \nas\n \nan\n \nexternal\n \nenvironment\n \nvariable\n \nto\n \nbe\n \nprogrammatically\n \nqueried,\n \nthe\n \nRLM\n \nseparates\n \nthe\n \nstorage\n \nof\n \ninformation\n \nfrom\n \nthe\n \nprocessing\n \nof\n \nreasoning.\n1  \nThis  report  investigates  the  feasibility  of  transplanting  the  theoretical  RLM  architecture  into  \nClaude\n \nCode\n,\n \nAnthropic's\n \nagentic\n \ncommand-line\n \ninterface.\n \nOur\n \nanalysis\n \nsuggests\n \nthat\n \nClaude\n \nCode\n \nprovides\n \na\n \nuniquely\n \nsuitable\n \nsubstrate\n \nfor\n \na\n \n\"Cannot\n \nFail\"\n \nRLM\n \nimplementation\n \ndue\n \nto\n \nits\n \npersistent\n \nshell\n \nenvironment,\n \nrobust\n \nlifecycle\n \nhook\n \nsystem,\n \nand\n \nnative\n \nsub-agent\n \ncapabilities.\n2\n Unlike  standard  chat  interfaces  or  Integrated  Development  Environment  (IDE)  \nplugins,\n \nClaude\n \nCode’s\n \nRead-Eval-Print\n \nLoop\n \n(REPL)\n \nnature\n \naligns\n \nperfectly\n \nwith\n \nthe\n \nRLM\n \nrequirement\n \nfor\n \na\n \npersistent\n \nexecution\n \nenvironment\n \ncapable\n \nof\n \nsymbolic\n \nmanipulation\n \nand\n \nrecursive\n \nself-invocation.\n1  \nWe  propose  a  robust  implementation  architecture  that  leverages  Claude  Code’s  SessionStart  \nhooks\n \nto\n \ninitialize\n \nan\n \n\"RLM\n \nKernel,\"\n \nutilizes\n \nlocal\n \nfile\n \nsystems\n \nfor\n \n\"out-of-core\"\n \nmemory\n \nmanagement,\n \nand\n \nemploys\n \nsub-agents\n \nfor\n \nrecursive\n \ndepth\n \nhandling.\n \nThis\n \n\"Cannot\n \nFail\"\n \nsystem\n \nis\n \ndesigned\n \nto\n \nprevent\n \ncontext\n \noverflow\n \nerrors\n \nand\n \nreasoning\n \nhallucinations\n \nby\n \nenforcing\n \na\n \nstrict\n \nregime\n \nof\n \nprogrammatic\n \ncontext\n \ndecomposition\n \nand\n \nverification.\n \nThe\n \nfollowing\n \nanalysis\n \ndetails\n \nthe\n \ntheoretical\n \nunderpinnings,\n \nthe\n \nspecific\n \naffordances\n \nof\n \nthe\n \nClaude\n \nCode\n \nplatform,\n \nand\n \na\n \ncomprehensive\n \nimplementation\n \nstrategy\n \nthat\n \nbridges\n \nthe\n \ngap\n \nbetween\n \nacademic\n \ntheory\n \nand\n \nproduction-grade\n \nsoftware\n \nengineering.\n \n--- PAGE 2 ---\n1.  Theoretical  Foundation:  The  Recursive  Language  \nModel\n \nTo  validate  the  feasibility  of  the  RLM  architecture  within  the  specific  constraints  and  \ncapabilities\n \nof\n \nClaude\n \nCode,\n \none\n \nmust\n \nfirst\n \ndissect\n \nthe\n \ntheoretical\n \nrequirements\n \nestablished\n \nby\n \nthe\n \nfoundational\n \nresearch.\n \nThe\n \nRLM\n \nis\n \nnot\n \nmerely\n \nan\n \nagentic\n \nworkflow;\n \nit\n \nis\n \na\n \nfundamental\n \ninference\n \nstrategy\n \ndesigned\n \nto\n \nscale\n \ninference-time\n \ncompute\n \nto\n \nhandle\n \ninputs\n \nup\n \nto\n \ntwo\n \norders\n \nof\n \nmagnitude\n \nbeyond\n \nthe\n \nmodel's\n \nnative\n \ncontext\n \nwindow.\n1  \n1.1  The  Environmental  Prompt  Hypothesis  \nThe  central  insight  driving  the  RLM  architecture  is  that  massive  prompts  should  never  be  fed  \ndirectly\n \ninto\n \nthe\n \nneural\n \nnetwork's\n \ntransformer\n \nlayers\n \nin\n \ntheir\n \nentirety.\n \nInstead,\n \nthe\n \nprompt\n \n$P$\n \nis\n \ntreated\n \nas\n \nan\n \nimmutable\n \nvariable\n \nresiding\n \nin\n \nan\n \nexternal\n \nprogramming\n \nenvironment.\n1\n The  \nLLM\n \nacts\n \nas\n \na\n \ncontroller\n \nthat\n \ninteracts\n \nwith\n \n$P$\n \nthrough\n \na\n \nRead-Eval-Print\n \nLoop\n \n(REPL),\n \nmirroring\n \nthe\n \nway\n \na\n \nhuman\n \nanalyst\n \nmight\n \nquery\n \na\n \ndatabase\n \nrather\n \nthan\n \nmemorizing\n \nit.\n \nThis  interaction  is  characterized  by  symbolic  interaction ,  where  the  model  writes  code  to  \ninspect\n \nthe\n \nproperties\n \nof\n \n$P$\n \n(e.g.,\n \ndetermining\n \nlength\n \nvia\n \nlen(P)\n \nor\n \npreviewing\n \ncontent\n \nwith\n \nP[:1000])\n \nrather\n \nthan\n \nreading\n \nthe\n \ntext\n \nlinearly.\n \nThis\n \nallows\n \nthe\n \nmodel\n \nto\n \nform\n \na\n \nschema\n \nof\n \nthe\n \ninformation\n \nbefore\n \ncommitting\n \ncomputational\n \nresources\n \nto\n \nprocessing\n \nit.\n \nFurthermore,\n \nthe\n \nmodel\n \nemploys\n \nprogrammatic\n \ndecomposition\n,\n \nutilizing\n \nstring\n \nmanipulation\n \nor\n \nregular\n \nexpressions\n \nto\n \nsplit\n \n$P$\n \ninto\n \nmanageable\n \nchunks\n \n($c_1,\n \nc_2,...,\n \nc_n$).\n \nThis\n \ndecomposition\n \nis\n \nnot\n \narbitrary;\n \nit\n \nis\n \nguided\n \nby\n \nthe\n \nmodel's\n \ninitial\n \nsymbolic\n \ninspection,\n \nensuring\n \nthat\n \nsplit\n \npoints\n \nrespect\n \nthe\n \nsemantic\n \nstructure\n \nof\n \nthe\n \ndata.\n1\n Finally,  the  architecture  relies  on  recursive  \ninvocation\n,\n \nwhere\n \nthe\n \nmodel\n \ncalls\n \na\n \nfunction—denoted\n \nas\n \nllm_query(query,\n \nchunk)\n \nin\n \nthe\n \nliterature—which\n \nspawns\n \na\n \nnew\n \nindependent\n \nRLM\n \ninstance\n \nto\n \nprocess\n \nthe\n \nspecific\n \nchunk.\n \nThis\n \neffectively\n \nisolates\n \nthe\n \nreasoning\n \ncontext,\n \nensuring\n \nthat\n \nno\n \nsingle\n \ninstance\n \nis\n \noverwhelmed\n \nby\n \nirrelevant\n \ndata.\n1  \nThis  structure  effectively  transforms  an  $O(N^2)$  attention  problem  (where  processing  cost  \nscales\n \nquadratically\n \nwith\n \ninput\n \nlength\n \ndue\n \nto\n \nthe\n \nattention\n \nmechanism)\n \ninto\n \nan\n \nout-of-core\n \ndata\n \nprocessing\n \ntask.\n \nThe\n \nprocessing\n \ncost\n \nshifts\n \nto\n \na\n \nlinear\n \nor\n \nlog-linear\n \nfunction\n \nof\n \nthe\n \nnumber\n \nof\n \nrecursive\n \ncalls\n \nrequired\n \nto\n \ndistill\n \nthe\n \ninformation,\n \ndecoupling\n \nthe\n \nsize\n \nof\n \nthe\n \ndataset\n \nfrom\n \nthe\n \ncomplexity\n \nof\n \nthe\n \nreasoning\n \ntask.\n1  \n1.2  Failure  Modes  in  Standard  Architectures  \nThe  \"Cannot  Fail\"  designation  in  our  proposed  architecture  is  derived  from  its  ability  to  \nstructurally\n \naddress\n \nthe\n \nprimary\n \nfailure\n \nmodes\n \nidentified\n \nin\n \nstandard\n \nLong-Context\n \nLLMs.\n \nContext  Rot  is  the  primary  adversary.  Empirical  studies  show  that  even  in  models  with  \n\"infinite\"\n \ncontext\n \nwindows,\n \nperformance\n \ndegrades\n \nas\n \nthe\n \nlocation\n \nof\n \nthe\n \n\"needle\"\n \n(relevant\n \n--- PAGE 3 ---\ninformation)  shifts  or  as  the  volume  of  the  \"haystack\"  (irrelevant  context)  increases.\n1\n This  is  \nnot\n \nmerely\n \na\n \nretrieval\n \nfailure\n \nbut\n \na\n \nreasoning\n \nfailure;\n \nthe\n \nnoise\n \nof\n \nthe\n \nhaystack\n \ninterferes\n \nwith\n \nthe\n \nmodel's\n \nability\n \nto\n \nattend\n \nto\n \nthe\n \nsignal.\n \nBy\n \ncompartmentalizing\n \ndata\n \ninto\n \ndiscrete\n \nchunks,\n \nthe\n \nRLM\n \nensures\n \nthat\n \nthe\n \nsignal-to-noise\n \nratio\n \nin\n \nany\n \ngiven\n \ninference\n \npass\n \nremains\n \nhigh.\n \nAttention  Dilution  occurs  in  tasks  requiring  global  aggregation,  such  as  \"Find  all  pairs  of  \nusers\n \nwho\n \ninteracted\n \nwith...\"\n \nIn\n \nstandard\n \nmodels,\n \nmaintaining\n \nfocus\n \nacross\n \nmillions\n \nof\n \ntokens\n \nto\n \ntrack\n \ndistributed\n \nentities\n \nis\n \ncomputationally\n \nprohibitive\n \nand\n \nprone\n \nto\n \nerror.\n \nThe\n \nRLM\n \nhandles\n \nthis\n \nby\n \naggregating\n \nintermediate\n \nresults\n \nprogrammatically,\n \nshifting\n \nthe\n \nburden\n \nof\n \n\"memory\"\n \nfrom\n \nthe\n \nmodel's\n \nactivations\n \nto\n \na\n \nstructured\n \ndata\n \nstore\n \n(e.g.,\n \na\n \nlist\n \nor\n \ndatabase)\n \nmanaged\n \nby\n \nthe\n \nenvironment.\n1  \nMemory  Overflow  represents  the  hard  physical  limit  of  current  hardware.  Loading  10  million  \ntokens\n \ninto\n \na\n \nsingle\n \ninference\n \npass\n \nis\n \ncurrently\n \nimpossible\n \non\n \nstandard\n \ndeployment\n \nhardware\n \ndue\n \nto\n \nKV-cache\n \nlimitations.\n \nThe\n \nRLM\n \narchitecture\n \nmitigates\n \nthese\n \nby\n \nstrictly\n \nenforcing\n \nthat\n \nno\n \nsingle\n \nmodel\n \ninstance\n \never\n \nsees\n \nmore\n \ncontext\n \nthan\n \nit\n \ncan\n \nreliably\n \nreason\n \nover\n \n(e.g.,\n \n<100k\n \ntokens),\n \ndelegating\n \nthe\n \nrest\n \nto\n \nsub-calls.\n1\n The  system  \"cannot  fail\"  due  to  context  limits  \nbecause\n \nit\n \nnever\n \nattempts\n \nto\n \ningest\n \nthe\n \nfull\n \ncontext\n \nat\n \nonce.\n \n2.  Claude  Code  Environment  Feasibility  Analysis  \nClaude  Code,  Anthropic's  developer-focused  Command  Line  Interface  (CLI)  tool,  presents  a  \nunique\n \noperational\n \nenvironment\n \nthat\n \nmirrors\n \nthe\n \ntheoretical\n \nrequirements\n \nof\n \nan\n \nRLM\n \nmore\n \nclosely\n \nthan\n \nstandard\n \nchat\n \ninterfaces,\n \nIDE\n \nplugins,\n \nor\n \neven\n \ntraditional\n \nagent\n \nframeworks.\n \nIts\n \narchitecture\n \nas\n \na\n \npersistent,\n \nstateful\n \nshell\n \nsession\n \nis\n \nkey\n \nto\n \nthis\n \nalignment.\n \n2.1  The  Persistent  REPL  Environment  \nThe  RLM  requires  a  persistent  environment  where  variables  (specifically  the  prompt  variable)  \ncan\n \nreside\n \nin\n \nmemory\n \nor\n \non\n \ndisk\n \nwhile\n \nthe\n \nmodel\n \niterates\n \nthrough\n \nits\n \nreasoning\n \nloops.\n \nClaude\n \nCode\n \noperates\n \nas\n \na\n \nstateful\n \nCLI\n \nsession\n \nthat\n \nmaintains\n \na\n \npersistent\n \nbash\n \nshell\n \nand\n \ndirectory\n \ncontext.\n2\n This  persistence  is  not  merely  a  convenience;  it  is  an  architectural  necessity  for  RLM.  \nThe  Bash  Tool  is  Claude  Code’s  primary  interface  with  the  host  system.  It  allows  the  agent  to  \nexecute\n \nsystem\n \ncommands,\n \nread\n \nfiles,\n \nand\n \npipe\n \noutputs.\n6\n This  functionality  is  equivalent  to  \nthe\n \nPython\n \nREPL\n \ndescribed\n \nin\n \nthe\n \nRLM\n \npaper\n \nbut\n \noffers\n \narguably\n \ngreater\n \npower\n \nby\n \naccessing\n \nthe\n \nfull\n \nOperating\n \nSystem\n \n(OS)\n \ntoolset.\n \nTools\n \nlike\n \ngrep,\n \nripgrep,\n \nand\n \nawk\n \nallow\n \nfor\n \nhigh-speed\n \n\"filtering\"\n \nof\n \ncontext\n \nbefore\n \nit\n \nis\n \never\n \nread\n \ninto\n \nthe\n \nmodel's\n \ncontext\n \nwindow,\n \nacting\n \nas\n \na\n \npre-attention\n \nmechanism\n \nmanaged\n \nby\n \nthe\n \nOS\n \nkernel\n \nrather\n \nthan\n \nthe\n \ntransformer.\n \nFurthermore,  the  introduction  of  the  Code  Execution  Tool  (currently  in  beta)  enables  \nsandboxed\n \nPython\n \nexecution.\n7\n This  allows  for  the  precise  import  capabilities  and  variable  \nmanipulation\n \nrequired\n \nby\n \nthe\n \nRLM\n \n\"Kernel.\"\n \nCrucially,\n \nthis\n \nPython\n \nenvironment\n \ncan\n \nbe\n \nconfigured\n \nto\n \nmaintain\n \nstate\n \nacross\n \nturns,\n \nor\n \nat\n \nminimum,\n \nstate\n \ncan\n \nbe\n \nserialized\n \nto\n \ndisk\n \nand\n \n--- PAGE 4 ---\nreloaded,  satisfying  the  requirement  for  variable  persistence.\n9  \n2.2  Recursion  via  Sub-agents  and  CLI  \nRecursion  is  the  engine  of  the  RLM,  enabling  the  system  to  \"drill  down\"  into  data.  Claude  Code  \nsupports\n \nthis\n \nthrough\n \ntwo\n \ndistinct\n \nand\n \ncomplementary\n \nmechanisms.\n \nFirst,  Native  Sub-agents  provide  a  structured  way  to  delegate  tasks.  Claude  Code  can  spawn  \nspecialized\n \n\"Sub-agents\"\n \n(via\n \nthe\n \nTask\n \ntool)\n \nto\n \nhandle\n \nspecific\n \nsub-tasks\n \nwith\n \nisolated\n \ncontext\n \nwindows.\n3\n This  directly  maps  to  the  llm_query  recursive  call  described  in  the  RLM  literature.  \nEach\n \nsub-agent\n \noperates\n \nindependently,\n \nprocessing\n \nits\n \nassigned\n \nchunk\n \nof\n \ndata\n \nwithout\n \npolluting\n \nthe\n \ncontext\n \nof\n \nthe\n \nparent\n \nagent.\n \nThe\n \nparent\n \nagent\n \nacts\n \nas\n \nthe\n \norchestrator,\n \nreceiving\n \nonly\n \nthe\n \ndistilled\n \noutput.\n10  \nSecond,  Recursive  CLI  Calls  offer  a  more  raw,  process-level  form  of  recursion.  Since  Claude  \nCode\n \nis\n \na\n \nCLI\n \ntool,\n \nit\n \ncan\n \ntheoretically\n \ninvoke\n \nitself\n \n(claude\n \n-p\n \n\"query\")\n \nfrom\n \nwithin\n \nits\n \nown\n \nbash\n \nshell.\n11\n This  creates  a  process-level  recursion  stack,  where  each  child  process  is  a  \ncompletely\n \nfresh\n \ninstance\n \nof\n \nthe\n \nClaude\n \nCode\n \nagent.\n \nThis\n \nmethod\n \noffers\n \nextreme\n \nisolation\n \nbut\n \ncomes\n \nwith\n \nhigher\n \noverhead.\n \nIt\n \nis\n \nparticularly\n \nuseful\n \nfor\n \n\"headless\"\n \noperations\n \nwhere\n \na\n \nsub-task\n \nneeds\n \nto\n \nbe\n \nexecuted\n \npurely\n \nfor\n \nits\n \nside\n \neffects\n \n(e.g.,\n \ngenerating\n \na\n \nfile)\n \nor\n \nits\n \nstandard\n \noutput.\n13  \n2.3  Context  Management  and  \"Out-of-Core\"  Storage  \nFor  the  system  to  be  \"Cannot  Fail,\"  it  must  handle  prompts  larger  than  the  context  window  \nwithout\n \ncrashing\n \nor\n \ntruncating\n \ncritical\n \ndata.\n \nClaude\n \nCode\n \nexcels\n \nin\n \nthis\n \nregard\n \nby\n \ntreating\n \nthe\n \nFilesystem\n \nas\n \nMemory\n.\n \nUnlike\n \na\n \nbrowser\n \nchat,\n \nwhich\n \nexists\n \nin\n \na\n \nsandbox\n \nisolated\n \nfrom\n \nlocal\n \nstorage,\n \nClaude\n \nCode\n \nhas\n \ndirect\n \nread/write\n \naccess\n \nto\n \nthe\n \nlocal\n \nfilesystem.\n \nA\n \n100MB\n \ntext\n \nfile\n \n(approx.\n \n25\n \nmillion\n \ntokens)\n \ncan\n \nsit\n \non\n \nthe\n \ndisk—effectively\n \n\"Out-of-Core\"—and\n \nbe\n \nqueried\n \nvia\n \ngrep\n \nor\n \nread\n \ncommands\n \nwithout\n \never\n \nbeing\n \nfully\n \nloaded\n \ninto\n \nthe\n \nconversation\n \nhistory.\n14  \nWhile  Claude  Code  has  built-in  mechanisms  for  Context  Compaction  (/compact),  which  \nsummarizes\n \nhistory\n \nto\n \nsave\n \ntokens\n \n16\n,  the  RLM  architecture  circumvents  the  need  for  \naggressive,\n \nlossy\n \ncompaction\n \nby\n \nkeeping\n \nthe\n \nprimary\n \ndata\n \nexternal.\n \nThe\n \ncontext\n \nwindow\n \nis\n \nreserved\n \nfor\n \nreasoning\n \nsteps\n \nand\n \ncode,\n \nnot\n \nfor\n \nraw\n \ndata\n \nstorage.\n \nThis\n \naligns\n \nwith\n \nthe\n \n\"Just-in-Time\"\n \n(JIT)\n \nretrieval\n \nstrategy\n \ndiscussed\n \nin\n \nrecent\n \nanalyses\n \nof\n \nagentic\n \nworkflows,\n \nwhere\n \ninformation\n \nis\n \nfetched\n \nonly\n \nat\n \nthe\n \nexact\n \nmoment\n \nof\n \nnecessity.\n14  \n2.4  Comparative  Capability  Analysis  \nTo  rigorously  evaluate  Claude  Code's  suitability,  we  must  compare  its  features  against  the  \nstrict\n \nrequirements\n \nof\n \nthe\n \nRLM\n \nspecification\n \nand\n \ncontrast\n \nthem\n \nwith\n \nstandard\n \nLLM\n \ninference\n \nmethods.\n \n--- PAGE 5 ---\nThe  following  table  details  the  mapping  between  RLM  requirements  and  Claude  Code's  \ncapabilities,\n \nhighlighting\n \nthe\n \nfeasibility\n \nof\n \nthe\n \nproposed\n \narchitecture.\n \n RLM  Requirement  Specification  Detail  \nClaude  Code  Capability  \nFeasibility  Assessment  \nPersistent  REPL  Environment  must  maintain  state  (variables)  between  inference  steps.  \nHigh:  Persistent  Bash  shell  \n6\n;  Python  REPL  via  MCP  or  Code  Execution.\n9\n State  can  be  serialized  to  disk.  \nConfirmed:  Native  Bash  persistence  is  robust;  Python  persistence  achievable  via  MCP  or  serialization.  \nRecursive  Invocation  \nModel  must  be  able  to  spawn  independent  instances  of  itself.  \nHigh:  Native  Sub-agents  (Task  tool)  \n3\n;  Recursive  CLI  calls  (claude  -p).\n12  \nConfirmed:  Dual  mechanisms  exist.  Sub-agents  are  preferred  for  context  isolation;  CLI  for  process  isolation.  \nExternal  Context  Prompt  must  be  treated  as  an  external  variable,  not  input  tokens.  \nHigh:  Direct  filesystem  access.  Data  resides  on  disk  (\"Out-of-Core\")  and  is  queried  via  tools.\n14  \nConfirmed:  Filesystem  acts  as  infinite  L2  cache.  grep/read  serve  as  the  interface.  \nSymbolic  Manipulation  \nModel  must  be  able  to  inspect  and  split  the  prompt  programmatically.  \nHigh:  Full  access  to  standard  Linux/Unix  tools  (awk,  sed,  split,  python).\n6  \nConfirmed:  The  environment  provides  superior  manipulation  tools  compared  to  a  standard  Python  sandbox.  \nDeterministic  Guardrails  \nSystem  must  prevent  unauthorized  direct  \nMedium/High:  Hook  system  (PreToolUse,  \nConfirmed:  Hooks  provide  the  necessary  \n--- PAGE 6 ---\nreading  of  massive  prompts.  \nSessionStart)  can  intercept  and  block  dangerous  commands.\n18  \ninterception  layer  to  enforce  the  \"Cannot  Fail\"  protocols.  \nThis  evaluation  confirms  that  Claude  Code  meets  all  critical  infrastructure  requirements  for  an  \nRLM.\n \nThe\n \nspecific\n \ncombination\n \nof\n \npersistent\n \nshell\n \naccess,\n \nfilesystem\n \ncontrol,\n \nand\n \nlifecycle\n \nhooks\n \ncreates\n \nan\n \nenvironment\n \nwhere\n \nthe\n \nabstract\n \ncomponents\n \nof\n \nthe\n \nRLM\n \ncan\n \nbe\n \ninstantiated\n \nas\n \nconcrete\n \nsoftware\n \nartifacts.\n \n \n  \n3.  The  'Cannot  Fail'  RLM  Embedded  Architecture  \nThe  \"Cannot  Fail\"  architecture  defines  a  system  where  the  risk  of  context  overflow  or  \nreasoning\n \nfailure\n \nis\n \nstructurally\n \neliminated\n \nby\n \nthe\n \nenvironment\n \nsetup.\n \nWe\n \ndefine\n \nthis\n \narchitecture\n \nas\n \nThe\n \nRLM-C\n \n(Recursive\n \nLanguage\n \nModel\n \non\n \nClaude)\n \nSystem\n.\n \nThis\n \nsystem\n \nrelies\n \non\n \nan\n \n\"Inversion\n \nof\n \nControl\"\n \nwhere\n \nthe\n \nuser\n \ndoes\n \nnot\n \nprompt\n \nthe\n \nmodel\n \ndirectly\n \nwith\n \n\n--- PAGE 7 ---\ndata,  but  rather  initializes  a  kernel  that  mediates  all  data  interaction.  \n3.1  The  RLM  Kernel:  Inversion  of  Control  \nIn  a  standard  session,  the  user  pastes  a  prompt  into  Claude.  In  the  RLM-C  architecture,  we  \ninvert\n \nthis.\n \nThe\n \nsession\n \nis\n \ninitialized\n \nwith\n \na\n \n\"Kernel\"—a\n \nPython\n \nor\n \nBash\n \nscript\n \nthat\n \nmediates\n \nall\n \ninteraction\n \nbetween\n \nthe\n \nmodel\n \nand\n \nthe\n \ndata.\n1  \nThe  Kernel  is  loaded  immediately  upon  session  start  via  the  SessionStart  hook.\n18\n This  hook  is  \nthe\n \nlinchpin\n \nof\n \nthe\n \narchitecture;\n \nit\n \ninjects\n \nthe\n \nRLM\n \nprimitives\n \n(functions\n \nfor\n \nchunking,\n \nquerying,\n \nand\n \naggregating)\n \ninto\n \nthe\n \nactive\n \nenvironment\n \nbefore\n \nthe\n \nuser\n \ncan\n \neven\n \nissue\n \na\n \ncommand.\n \nThis\n \nensures\n \nthat\n \nthe\n \nRLM\n \ncapabilities\n \nare\n \nomnipresent\n \nand\n \nthat\n \nthe\n \nenvironment\n \nis\n \npre-configured\n \nto\n \nhandle\n \nlarge\n \ndata.\n \nThe  Prompt  Variable  is  redefined.  The  massive  input  context  is  not  pasted  into  the  chat.  \nInstead,\n \nit\n \nis\n \nsaved\n \nto\n \na\n \npersistent\n \nfile\n \n(e.g.,\n \ncontext.txt,\n \ncorpus.sqlite,\n \nor\n \na\n \nspecialized\n \n.mcp\n \nstorage)\n \nin\n \nthe\n \nworkspace.\n \nThe\n \nKernel\n \nexposes\n \na\n \nhandle\n \nto\n \nthis\n \nfile\n \n(e.g.,\n \nan\n \nenvironment\n \nvariable\n \nCTX_FILE=\"context.txt\").\n \nThe\n \nmodel\n \ninteracts\n \nwith\n \nthis\n \nhandle,\n \nnot\n \nthe\n \ncontent\n \nitself.\n \nCrucially,  the  Root  Instruction  is  embedded  in  the  system  prompt  (via  CLAUDE.md  or  the  \n--system-prompt\n \nflag).\n \nThis\n \ninstruction\n \nexplicitly\n \nforbids\n \nClaude\n \nfrom\n \nreading\n \nCTX_FILE\n \ndirectly.\n \nInstead,\n \nit\n \nmandates\n \nthat\n \nClaude\n \ninteracts\n \nwith\n \nthe\n \ndata\n \nonly\n \nvia\n \nthe\n \nKernel\n \ntools.\n1\n This  \ninstruction\n \nacts\n \nas\n \nthe\n \n\"prime\n \ndirective\"\n \nof\n \nthe\n \nRLM-C\n \nsystem,\n \nenforcing\n \nthe\n \narchitectural\n \nconstraints\n \nat\n \nthe\n \ninference\n \nlevel.\n \n3.2  Recursive  Depth  via  Sub-Agents  \nThe  RLM  paper  utilizes  llm_query  for  recursion.  In  Claude  Code,  this  maps  directly  to  the  \nSub-agent\n \narchitecture.\n3  \nThe  Supervisor  (Root  Agent)  holds  the  high-level  goal  (e.g.,  \"Find  the  answer  in  this  10MB  \nbook\").\n \nIt\n \ndoes\n \nnot\n \nattempt\n \nto\n \nread\n \nthe\n \nbook.\n \nInstead,\n \nit\n \nexecutes\n \nKernel\n \ncode\n \nto\n \nsplit\n \nthe\n \nbook\n \ninto\n \nchapters\n \nor\n \nlogical\n \nsections.\n \nIt\n \nacts\n \nas\n \na\n \nmanager,\n \ndistributing\n \nwork\n \nrather\n \nthan\n \ndoing\n \nit.\n \nThe  Worker  (Sub-agent)  is  instantiated  by  the  Supervisor  for  each  chunk  of  work.  The  \nSupervisor\n \ncalls\n \na\n \nsub-agent\n \n(using\n \nnatural\n \nlanguage\n \ndelegation\n \nor\n \nthe\n \nAgent\n \ntool)\n \nfor\n \neach\n \nchapter.\n ●  Input:  The  sub-agent  receives  only  the  specific  chunk  (Chapter  1)  and  the  specific  query  \nrelevant\n \nto\n \nthat\n \nchunk.\n ●  Constraint:  The  sub-agent  starts  with  a  fresh,  empty  context  window.  It  processes  only  \nthe\n \nchunk\n \nit\n \nis\n \ngiven,\n \nensuring\n \nthat\n \nits\n \nreasoning\n \ncapacity\n \nis\n \nnot\n \ndiluted\n \nby\n \nthe\n \nrest\n \nof\n \nthe\n \ndataset.\n ●  Output:  The  sub-agent  returns  a  concise  \"Sub-Response\"  to  the  Supervisor.  This  \nresponse\n \nis\n \na\n \ndistilled\n \nsynthesis\n \nof\n \nthe\n \nchunk,\n \nnot\n \na\n \nreproduction\n \nof\n \nit.\n \n--- PAGE 8 ---\nTo  ensures  \"Cannot  Fail\"  reliability,  the  Kernel  enforces  a  Max  Recursion  Depth  and  a  Token  \nBudget\n \nfor\n \neach\n \nsub-agent\n \ncall.\n10\n If  a  sub-agent  attempts  to  spawn  further  sub-agents  \nbeyond\n \na\n \nsafe\n \ndepth\n \n(e.g.,\n \n3\n \nlevels),\n \nthe\n \nKernel\n \nblocks\n \nthe\n \nrequest,\n \npreventing\n \ninfinite\n \nloops\n \nor\n \n\"fork\n \nbomb\"\n \nscenarios\n \nwhere\n \ncosts\n \nexplode\n \nexponentially.\n \n3.3  Out-of-Core  Memory  Management  \nTo  handle  10M+  tokens,  the  system  treats  the  local  filesystem  as  a  Level  2  (L2)  cache ,  while  \nthe\n \ncontext\n \nwindow\n \nacts\n \nas\n \na\n \nLevel\n \n1\n \n(L1)\n \ncache\n.\n \nIndexing  is  the  first  step  of  ingestion.  Upon  receiving  a  dataset,  the  Kernel  uses  tools  like  \nripgrep\n \nor\n \na\n \nlightweight\n \nvector\n \nstore\n \n(via\n \nMCP\n \nor\n \nlocal\n \nPython\n \nlibraries\n \nlike\n \nchromadb\n \nor\n \nsqlite-vec)\n \nto\n \ncreate\n \nan\n \nindex\n \nof\n \nthe\n \ndata.\n22\n This  index  allows  for  rapid,  targeted  retrieval  \nwithout\n \nlinear\n \nscanning.\n \nPaging  is  used  when  a  sub-agent  needs  data.  The  Kernel  \"pages\"  data  in  from  the  L2  cache  \n(filesystem).\n \nIt\n \nreads\n \nspecific\n \nlines,\n \nbytes,\n \nor\n \nlogical\n \nblocks\n \nfrom\n \nthe\n \nfile,\n \nensuring\n \nthe\n \nresult\n \nfits\n \ncomfortably\n \nwithin\n \nthe\n \nsub-agent's\n \n200k\n \ntoken\n \ncontext\n \nlimit.\n \nAggregation  of  results  is  handled  carefully.  Results  from  sub-agents  are  not  simply  \nconcatenated\n \ninto\n \nthe\n \nSupervisor's\n \ncontext\n \nwindow,\n \nas\n \nthis\n \nwould\n \neventually\n \ncause\n \nan\n \noverflow.\n \nInstead,\n \nthey\n \nare\n \nwritten\n \nto\n \na\n \nresults.json\n \nfile\n \non\n \ndisk.\n \nThe\n \nSupervisor\n \nthen\n \nreads\n \nsummaries\n \nof\n \nthese\n \nresults\n \nor\n \nqueries\n \nthe\n \nresults\n \nfile\n \niteratively\n \nto\n \nbuild\n \nthe\n \nfinal\n \nanswer.\n1\n This  \nensures\n \nthat\n \nthe\n \nSupervisor's\n \ncontext\n \nremains\n \nstable\n \nregardless\n \nof\n \nthe\n \namount\n \nof\n \nwork\n \nperformed\n \nby\n \nthe\n \nsub-agents.\n \n4.  Implementation  Strategy:  A  robust  \"How-To\"  \nThis  section  details  the  practical  implementation  of  the  RLM-C  architecture  using  Claude  \nCode’s\n \nconfiguration\n \ncapabilities.\n \nIt\n \ntranslates\n \nthe\n \narchitectural\n \nconcepts\n \ninto\n \nspecific\n \ncode\n \nand\n \nconfiguration\n \nsteps.\n \n4.1  Step  1:  The  Environment  Configuration  (Hooks)  \nThe  foundation  of  the  system  is  the  SessionStart  hook.  This  hook  ensures  the  RLM  \nenvironment\n \nis\n \nactive\n \nin\n \nevery\n \nsession,\n \nguaranteeing\n \nthe\n \n\"Cannot\n \nFail\"\n \nstate\n \nby\n \npreventing\n \nthe\n \nuser\n \n(or\n \nClaude)\n \nfrom\n \naccidentally\n \nentering\n \na\n \nstandard,\n \nnon-recursive\n \nmode\n \nwhere\n \nthey\n \nmight\n \nattempt\n \nto\n \nread\n \na\n \nmassive\n \nfile\n \ndirectly.\n \nWe  configure  the  .claude/settings.json  file  to  load  our  environment  script.  This  JSON  \nconfiguration\n \ndefines\n \nthe\n \ntriggers\n \nfor\n \nour\n \nRLM\n \ninitialization.\n \n \n--- PAGE 9 ---\nJSON  \n  {  \n  \"hooks\":  {  \n    \"SessionStart\":  [  \n      \n{\n \n        \"matcher\":  \"startup\",  \n        \"hooks\":  [  \n          \n{\n \n            \"type\":  \"command\",  \n            \"command\":  \"source.claude/rlm_kernel.sh  &&  python3.claude/init_rlm.py\" \n          \n}\n \n        \n]\n \n      \n}\n \n    \n],\n \n    \"PreToolUse\":  \n      \n}\n \n    \n]\n \n  \n}\n \n}\n \n The  SessionStart  hook  initializes  the  environment.\n18\n It  runs  a  shell  script  to  set  environment  \nvariables\n \n(like\n \nCTX_FILE)\n \nand\n \na\n \nPython\n \nscript\n \n(init_rlm.py)\n \nthat\n \nmight\n \nstart\n \na\n \nbackground\n \nMCP\n \nserver\n \nor\n \ndefine\n \nhelper\n \nfunctions.\n \nIt\n \nis\n \ncrucial\n \nto\n \nnote\n \nthat\n \nSessionStart\n \nhooks\n \ncan\n \nbe\n \nbrittle;\n \ntheir\n \nstdout\n \nis\n \nnot\n \nalways\n \nvisible\n \nto\n \nthe\n \nuser,\n \nand\n \nthey\n \nmust\n \nrely\n \non\n \nside\n \neffects\n \n(like\n \nsetting\n \nenvironment\n \nvariables\n \nor\n \ncreating\n \nfiles)\n \nto\n \nbe\n \neffective.\n19  \nThe  PreToolUse  hook  acts  as  the  system's  safety  valve  or  firewall.\n18\n It  intercepts  every  \nattempt\n \nby\n \nClaude\n \nto\n \nuse\n \nthe\n \nRead\n \ntool.\n \nThe\n \nguardrails.py\n \nscript\n \nchecks\n \nthe\n \nsize\n \nof\n \nthe\n \ntarget\n \nfile.\n \nIf\n \nthe\n \nfile\n \nsize\n \nexceeds\n \na\n \nsafe\n \nthreshold\n \n(e.g.,\n \n500KB),\n \nthe\n \nhook\n \nblocks\n \nthe\n \nread\n \noperation\n \nand\n \nreturns\n \na\n \nsystem\n \nmessage\n \nto\n \nClaude:\n \n\"File\n \ntoo\n \nlarge\n \nfor\n \ndirect\n \ncontext.\n \nUse\n \nrlm_query\n \nor\n \nchunk_read\n \ninstead.\"\n \nThis\n \nfeedback\n \nloop\n \nforces\n \nthe\n \nmodel\n \nto\n \nadopt\n \nthe\n \nRLM\n \npattern,\n \neffectively\n \n\"teaching\"\n \nit\n \nthe\n \nconstraints\n \nof\n \nthe\n \nenvironment.\n \n4.2  Step  2:  The  RLM  Kernel  (Python/MCP)  \nThe  Kernel  is  the  set  of  tools  exposed  to  Claude.  While  raw  Bash  scripts  can  suffice  for  simple  \ntasks,\n \na\n \nPython-based\n \nModel\n \nContext\n \nProtocol\n \n(MCP)\n \nserver\n \nor\n \na\n \nset\n \nof\n \nPython\n \nscripts\n \nis\n \nmore\n \nrobust\n \nfor\n \ncomplex\n \ndata\n \nmanipulation.\n \nFor\n \na\n \nlightweight\n \nembedded\n \nsystem,\n \nwe\n \ndefine\n \nthese\n \nas\n \nsimple\n \nPython\n \nscripts\n \nthat\n \nClaude\n \nexecutes\n \nvia\n \nthe\n \nBash\n \ntool\n \nor\n \nthe\n \nCode\n \nExecution\n \nenvironment.\n \n--- PAGE 10 ---\nKey  Kernel  functions  implemented  in  rlm_lib.py  include:  1.  chunk_data(source_path,  chunk_size=5000) :  This  function  splits  a  large  source  file  \ninto\n \ntemporary\n \nchunk\n \nfiles\n \n(e.g.,\n \n.cache/chunk_001.txt).\n \nIt\n \nmanages\n \nthe\n \n\"physical\"\n \ndecomposition\n \nof\n \nthe\n \nprompt\n \nvariable.\n 2.  delegate_task(instruction,  context_file) :  This  is  the  critical  recursive  function.  ○  It  constructs  a  tailored  prompt:  \"You  are  a  Sub-agent  processing  a  chunk.  Read  \n{context_file}.\n \nAnswer:\n \n{instruction}.\"\n ○  It  then  calls  claude  -p  (Print  Mode)  or  invokes  a  Sub-agent  via  the  Agent  tool  to  \nprocess\n \nthis\n \nsingle\n \nchunk.\n12  \n○  Crucially,  it  captures  the  text  output  of  this  sub-call  and  writes  it  to  a  partial_result  \nvariable\n \nor\n \nfile,\n \npreventing\n \nit\n \nfrom\n \nflooding\n \nthe\n \ncurrent\n \ncontext.\n 3.  aggregate_results(pattern) :  This  function  reads  all  partial  results  generated  by  the  \nsub-agents\n \nand\n \nprepares\n \nthem\n \nfor\n \nfinal\n \nsynthesis,\n \ntypically\n \nby\n \nconcatenating\n \nthem\n \ninto\n \na\n \nnew\n \nsummary\n \nfile\n \nor\n \ndatabase\n \nview.\n \n4.3  Step  3:  Configuring  the  System  Prompt  (CLAUDE.md)  \nThe  CLAUDE.md  file  serves  as  the  \"BIOS\"  or  operating  manual  for  the  RLM  system.  It  instructs  \nthe\n \nmodel\n \non\n \nits\n \nown\n \narchitecture,\n \ndefining\n \nthe\n \nrules\n \nof\n \nengagement.\n26\n Without  this,  the  model  \nhas\n \nno\n \nway\n \nof\n \nknowing\n \nit\n \nis\n \noperating\n \nwithin\n \nan\n \nRLM\n \nconstraint\n \nsystem.\n \nProposed  CLAUDE.md  Content:  \n\"You  are  running  in  RLM  Mode.  You  DO  NOT  have  infinite  context.  You  have  access  \nto\n \na\n \nmassive\n \nexternal\n \n'Environment'.\n \nPROTOCOL:  1.  Never  read  large  files  directly.  Check  file  size  with  ls  -lh  first.  2.  Use  the  Kernel.  To  process  large  data,  use  python3  rlm_lib.py  chunk...  3.  Recursive  Delegation.  If  a  task  covers  >5  files  or  >50k  tokens,  you  MUST  \nspawn\n \na\n \nsub-task\n \nfor\n \neach\n \ncomponent\n \nusing\n \ndelegate_task.\n 4.  Verification.  Before  answering,  verify  your  findings  by  running  a  specific  \ngrep\n \nor\n \npython\n \ncheck.\n Failure  to  follow  this  protocol  will  trigger  the  PreToolUse  guardrails.\"  \nThis  prompt  explicitly  aligns  the  model's  behavior  with  the  constraints  enforced  by  the  hooks,  \ncreating\n \na\n \ncoherent\n \nsystem\n \nwhere\n \nthe\n \nmodel's\n \n\"internal\"\n \ninstructions\n \nmatch\n \nthe\n \n\"external\"\n \nreality\n \nof\n \nthe\n \nenvironment.\n \n4.4  Advanced  Configuration:  Python  Environment  Persistence  \nA  critical  challenge  in  implementing  the  RLM  Kernel  is  ensuring  that  the  Python  environment  \npersists\n \nacross\n \ndifferent\n \ntool\n \ncalls.\n \nBy\n \ndefault,\n \neach\n \npython\n \ncommand\n \nin\n \na\n \nshell\n \nmight\n \nrun\n \nin\n \na\n \n--- PAGE 11 ---\nfresh  process,  losing  variables  defined  in  previous  steps.  \nTo  solve  this,  we  can  leverage  the  PYTHONSTARTUP  environment  variable.\n27\n By  setting  export  \nPYTHONSTARTUP=$HOME/.claude/rlm_startup.py\n \nin\n \nthe\n \nSessionStart\n \nhook\n \nor\n \nthe\n \nuser's\n \nshell\n \nprofile,\n \nwe\n \nensure\n \nthat\n \nevery\n \ntime\n \nClaude\n \ninvokes\n \npython,\n \nit\n \npre-loads\n \nthe\n \nRLM\n \nlibrary\n \nand\n \npotentially\n \nre-hydrates\n \nstate\n \nfrom\n \na\n \nserialization\n \nfile.\n \nThis\n \nmimics\n \nthe\n \npersistent\n \nstate\n \nof\n \na\n \nJupyter\n \nnotebook\n \nkernel\n \nbut\n \nwithin\n \nthe\n \nrobust,\n \nscriptable\n \nenvironment\n \nof\n \nthe\n \nCLI.\n27\n This  allows  \nClaude\n \nto\n \ndefine\n \na\n \nvariable\n \ndataset\n \n=\n \nload_data()\n \nin\n \none\n \nturn\n \nand\n \naccess\n \ndataset\n \nin\n \nthe\n \nnext,\n \nprovided\n \nthe\n \nPython\n \nsession\n \nis\n \nkept\n \nalive\n \nor\n \nstate\n \nis\n \nrestored.\n \nAdditionally,  managing  dependencies  with  modern  tools  like  uv  ensures  that  the  environment  \nis\n \nreproducible\n \nand\n \nfast.\n28\n The  SessionStart  hook  can  verify  that  uv  is  installed  and  that  the  \nvirtual\n \nenvironment\n \nis\n \nactive,\n \npreventing\n \n\"module\n \nnot\n \nfound\"\n \nerrors\n \nthat\n \nwould\n \nbreak\n \nthe\n \n\"Cannot\n \nFail\"\n \nguarantee.\n \n5.  Performance  &  Feasibility  Analysis  5.1  Cost  Analysis  \nThe  RLM  architecture  introduces  a  fundamental  trade-off:  it  increases  the  number  of  calls  but  \ndrastically\n \nreduces\n \nthe\n \ncontext\n \nsize\n \nper\n \ncall.\n \nConsider  the  task  of  analyzing  a  1  million  token  codebase.  ●  Base  Model  Approach  (GPT-5/Opus):  Loading  1M  tokens  into  the  context  window  once  \ncosts\n \napproximately\n \n$15\n \n(assuming\n \na\n \nhypothetical\n \npricing\n \nof\n \n$15\n \nper\n \n1M\n \ninput\n \ntokens).\n \nThis\n \nis\n \na\n \nsingle,\n \nexpensive\n \npoint\n \nof\n \nfailure.\n ●  RLM  Approach  (Sonnet/Haiku  mix):  The  Root  Agent  sees  only  metadata  and  file  lists  (a  \nvery\n \nsmall\n \ncontext).\n \nIt\n \nthen\n \nmakes,\n \nfor\n \nexample,\n \n100\n \nsub-calls.\n \nHowever,\n \nthese\n \nsub-calls\n \ncan\n \nbe\n \nrouted\n \nto\n \ncheaper,\n \nfaster\n \nmodels\n \nlike\n \nHaiku\n \nfor\n \nsimple\n \nextraction\n \ntasks\n \n(\"Find\n \nfunction\n \ndefinitions\n \nin\n \nthis\n \nfile\").\n \nOr\n \nthey\n \ncan\n \nuse\n \nsmall\n \nslices\n \nof\n \nSonnet\n \n(e.g.,\n \n10k\n \ntokens).\n ●  Feasibility:  The  original  RLM  paper  notes  that  RLM  costs  are  \"comparable  or  cheaper\"  to  \nmonolithic\n \ncalls.\n1\n In  the  context  of  Claude  Code,  using  claude  -p  with  Haiku  for  the  \nrecursive\n \nleaves\n \n(chunk\n \nprocessing)\n \nand\n \nOpus\n \nor\n \nSonnet\n \n3.5\n \nfor\n \nthe\n \nroot\n \n(synthesis)\n \ncreates\n \na\n \nhighly\n \ncost-effective\n \npipeline.\n29\n The  cost  becomes  proportional  to  the  relevant  \ninformation\n \nextracted,\n \nrather\n \nthan\n \nthe\n \ntotal\n \nirrelevant\n \ndata\n \nscanned.\n \n \n--- PAGE 12 ---\n  \n5.2  Latency  and  Throughput  \nA  naive  RLM  implementation  in  a  standard  REPL  is  serial:  the  model  issues  a  query,  waits  for  \nthe\n \nresult,\n \nand\n \nthen\n \nissues\n \nthe\n \nnext.\n \nThis\n \nblocks\n \non\n \nevery\n \ncall.\n \nOptimization:  Claude  Code's  Bash  tool  allows  for  background  processes  using  the  \nampersand\n \n(&)\n \noperator.\n \nThe\n \n\"Cannot\n \nFail\"\n \narchitecture\n \ncan\n \nleverage\n \nthis\n \nto\n \nlaunch\n \nmultiple\n \nclaude\n \n-p\n \nsub-tasks\n \nin\n \nparallel\n \nbackground\n \nprocesses.\n \nThis\n \ncreates\n \na\n \n\"Map-Reduce\"\n \nstyle\n \nworkflow\n \nwhere\n \nthe\n \nRoot\n \nAgent\n \nspawns\n \n10\n \nworkers\n \nto\n \nanalyze\n \n10\n \nchapters\n \nsimultaneously,\n \n\n--- PAGE 13 ---\nwaits  for  all  to  finish  (wait  command),  and  then  aggregates  the  results.  This  parallelization  \nsignificantly\n \nlowers\n \nthe\n \nwall-clock\n \ntime\n \ncompared\n \nto\n \na\n \nsingle\n \nmassive\n \nserial\n \nstream,\n \nmaking\n \nthe\n \nRLM\n \napproach\n \nnot\n \njust\n \nrobust\n \nbut\n \nalso\n \ntimely.\n25  \n5.3  Security  and  Sandboxing  \nThe  feasibility  of  RLM  also  hinges  on  security.  Allowing  an  LLM  to  execute  code  and  spawn  \nprocesses\n \ncarries\n \ninherent\n \nrisks.\n \nSandboxing:  Claude  Code's  native  sandboxing  (built  on  OS  primitives  like  bubblewrap  on  Linux  \nor\n \nseatbelt\n \non\n \nmacOS)\n \nprovides\n \na\n \ncrucial\n \nlayer\n \nof\n \ndefense.30\n \nIt\n \nrestricts\n \nthe\n \nagent's\n \nability\n \nto\n \nread\n \nfiles\n \noutside\n \nthe\n \nproject\n \ndirectory\n \nor\n \nmake\n \narbitrary\n \nnetwork\n \nconnections.\n Network  Policy:  For  the  RLM  to  work,  specifically  if  it  uses  claude  -p  (which  requires  \nauthentication),\n \nthe\n \nsandbox\n \nmust\n \nexplicitly\n \nallow\n \noutbound\n \nconnections\n \nto\n \napi.anthropic.com.31\n \nThe\n \nSessionStart\n \nhook\n \nor\n \nsettings.json\n \nmust\n \nbe\n \nconfigured\n \nto\n \nwhitelist\n \nthis\n \ndomain,\n \notherwise,\n \nthe\n \nrecursive\n \ncalls\n \nwill\n \nfail.\n dangerously-skip-permissions:  While  this  flag  enables  fully  autonomous  \"YOLO  mode\"  \noperation\n \n32,\n \nit\n \nis\n \ngenerally\n \ndiscouraged\n \nfor\n \nthe\n \n\"Cannot\n \nFail\"\n \narchitecture\n \nunless\n \nrunning\n \ninside\n \na\n \ndedicated,\n \ndisposable\n \ncontainer\n \n(like\n \na\n \nDocker\n \ncontainer).\n \nThe\n \n\"Cannot\n \nFail\"\n \nphilosophy\n \nprioritizes\n \nsafety\n \nand\n \ncorrectness\n \nover\n \nraw\n \nspeed;\n \ntherefore,\n \nthe\n \nrecommended\n \napproach\n \nis\n \na\n \nconfigured\n \nsandbox\n \nwith\n \nexplicit\n \nallow-lists\n \nfor\n \nthe\n \nRLM\n \nKernel\n \ntools,\n \nrather\n \nthan\n \ndisabling\n \nall\n \npermission\n \nchecks.\n \n6.  Risk  Mitigation:  Why  It  \"Cannot  Fail\"  \nThe  \"Cannot  Fail\"  moniker  is  bold.  To  justify  it,  the  system  must  handle  the  worst-case  \nscenarios\n \ninherent\n \nto\n \nagentic\n \nsystems.\n \n6.1  Infinite  Recursion  Prevention  \nRisk:  The  Root  Agent  delegates  to  a  Sub-agent,  which  delegates  back  to  the  Root,  creating  an  \ninfinite\n \nloop\n \n(fork\n \nbomb).33\n Solution:  The  RLM  Kernel  tracks  a  recursion_depth  variable  in  the  CLAUDE_ENV_FILE.  The  \nSessionStart\n \nhook\n \nincrements\n \nthis\n \non\n \nevery\n \nnested\n \ncall.\n \nIf\n \nrecursion_depth\n \n>\n \nMAX_DEPTH\n \n(e.g.,\n \n3),\n \nthe\n \nhook\n \nforces\n \nthe\n \nsession\n \nto\n \nabort\n \nor\n \nswitch\n \nto\n \na\n \n\"Leaf\n \nMode\"\n \nwhere\n \nno\n \nfurther\n \ntools\n \ncan\n \nbe\n \ncalled,\n \nforcing\n \na\n \nreturn\n \nvalue.1\n \nThis\n \nis\n \na\n \nhard\n \nstop\n \nimplemented\n \nin\n \nthe\n \nshell\n \nenvironment,\n \nindependent\n \nof\n \nthe\n \nmodel's\n \nbehavior.\n \n6.2  Context  Explosion  (The  \"Blowing  Up\"  Risk)  \nRisk:  A  sub-agent  reads  a  file  it  thinks  is  small,  but  it's  actually  a  2GB  log  file,  crashing  the  \nlocal\n \nmemory\n \nor\n \ncosting\n \nthousands\n \nof\n \ndollars.\n Solution:  The  PreToolUse  hook  defined  in  Section  4.1  acts  as  a  mandatory  firewall.  No  file  read  \nis\n \npermitted\n \nwithout\n \na\n \nsize\n \ncheck.\n \nFurthermore,\n \nthe\n \nread\n \ntool\n \nis\n \nwrapped\n \nto\n \nreturn\n \nonly\n \nthe\n \nfirst\n \n200\n \nlines\n \nby\n \ndefault,\n \nrequiring\n \nexplicit\n \npaging\n \nfor\n \nmore.18\n \nThis\n \nensures\n \nthat\n \n\"accidental\"\n \nlarge\n \nreads\n \nare\n \nimpossible.\n \n--- PAGE 14 ---\n6.3  Tool  Hallucination  \nRisk:  The  model  tries  to  call  a  Python  function  that  doesn't  exist  in  the  Kernel.  Solution:  The  Kernel  is  loaded  with  a  strictly  typed  interface  (e.g.,  using  Pydantic  or  similar  \nvalidation\n \nin\n \nthe\n \nPython\n \nscript).\n \nIf\n \nthe\n \nmodel\n \ncalls\n \nan\n \ninvalid\n \nfunction,\n \nthe\n \nREPL\n \nreturns\n \na\n \nstructured\n \nerror\n \nwith\n \nthe\n \nvalid\n \nschema,\n \nguiding\n \nthe\n \nmodel\n \nback\n \nto\n \nthe\n \ncorrect\n \npath\n \nimmediately.12\n \nThis\n \nself-correcting\n \nmechanism\n \nprevents\n \nthe\n \nagent\n \nfrom\n \ngetting\n \nstuck\n \nin\n \na\n \nhallucination\n \nloop.\n \n7.  Strategic  Recommendations  and  Best  Practices  \nTo  successfully  deploy  this  architecture,  we  recommend  the  following  phased  approach:  1.  Phase  1:  The  \"Harness\"  Development:  Do  not  start  with  the  model.  Build  the  rlm_lib.py  \nPython\n \nlibrary\n \nfirst.\n \nEnsure\n \nyour\n \nchunking,\n \nsearching,\n \nand\n \naggregation\n \nfunctions\n \nare\n \nrobust\n \nand\n \nunit-tested\n \noutside\n \nof\n \nClaude.\n \nThe\n \nRLM\n \nis\n \nonly\n \nas\n \ngood\n \nas\n \nits\n \nKernel.\n 2.  Phase  2:  Hook  Integration:  Install  the  SessionStart  and  PreToolUse  hooks.  Test  them  \naggressively.\n \nTry\n \nto\n \n\"break\"\n \nthe\n \nsystem\n \nby\n \nasking\n \nClaude\n \nto\n \nread\n \na\n \nmassive\n \nfile.\n \nEnsure\n \nthe\n \nguardrails\n \nhold.\n 3.  Phase  3:  Sub-agent  Tuning:  Experiment  with  claude  -p  calls.  Determine  the  optimal  \nprompt\n \nfor\n \nyour\n \nsub-agents.\n \nA\n \nlightweight\n \nmodel\n \n(Haiku)\n \noften\n \nperforms\n \nbetter\n \non\n \nfocused\n \n\"extract\n \nand\n \nsummarize\"\n \ntasks\n \nthan\n \na\n \nreasoning\n \nmodel\n \n(Opus),\n \nreducing\n \nboth\n \ncost\n \nand\n \nlatency.\n 4.  Phase  4:  Observable  Telemetry:  Use  Claude  Code's  logging  hooks  (PostToolUse)  to  \nrecord\n \nevery\n \nsub-call.\n \nYou\n \nneed\n \nvisibility\n \ninto\n \nthe\n \nrecursion\n \ntree\n \nto\n \ndebug\n \nlogic\n \nerrors.\n18  \nConclusion  \nThe  \"Cannot  Fail\"  RLM  architecture  is  not  a  theoretical  abstraction  but  a  deployable  reality  \nwithin\n \nthe\n \nClaude\n \nCode\n \necosystem.\n \nBy\n \nleveraging\n \nthe\n \nplatform's\n \npersistent\n \nREPL,\n \naggressive\n \nhook\n \nsystem,\n \nand\n \nsub-agent\n \ncapabilities,\n \ndevelopers\n \ncan\n \ncreate\n \nan\n \nembedded\n \nsystem\n \nthat\n \ntranscends\n \nthe\n \nlimitations\n \nof\n \nstandard\n \ncontext\n \nwindows.\n \nThis\n \narchitecture\n \nshifts\n \nthe\n \nburden\n \nof\n \nmemory\n \nfrom\n \nthe\n \nmodel's\n \nweights\n \nto\n \nthe\n \nsystem's\n \narchitecture,\n \nresulting\n \nin\n \na\n \nrobust,\n \nscalable,\n \nand\n \neconomically\n \nviable\n \nsolution\n \nfor\n \ndeep\n \nresearch\n \nand\n \nmassive-scale\n \ncode\n \nanalysis.\n \nThe\n \nkey\n \nto\n \nsuccess\n \nlies\n \nnot\n \nin\n \nthe\n \nmodel's\n \nintelligence,\n \nbut\n \nin\n \nthe\n \nrigidity\n \nof\n \nthe\n \nenvironmental\n \nconstraints—the\n \n\"Cannot\n \nFail\"\n \nguardrails—that\n \nsurround\n \nit.\n \nWorks  cited  \n1.  RLM  RESEARCH  PAPER.pdf  2.  Claude  Code  overview  -  Claude  Code  Docs,  accessed  on  January  5,  2026,  https://code.claude.com/docs/en/overview 3.  Subagents  -  Claude  Code  Docs,  accessed  on  January  5,  2026,  https://code.claude.com/docs/en/sub-agents 4.  Claude  Code:  A  Simple  Loop  That  Produces  High  Agency  |  by  AI4HUMAN  -  \nMedium,\n \naccessed\n \non\n \nJanuary\n \n5,\n \n2026,\n \n--- PAGE 15 ---\nhttps://medium.com/@aiforhuman/claude-code-a-simple-loop-that-produces-high-agency-814c071b455d 5.  Cooking  with  Claude  Code:  The  Complete  Guide  -  Sid  Bharath,  accessed  on  \nJanuary\n \n5,\n \n2026,\n https://www.siddharthbharath.com/claude-code-the-complete-guide/ 6.  [DOCS]  Environment  variables  don't  persist  between  bash  commands  -  \ndocumentation\n \ninconsistency\n \n·\n \nIssue\n \n#2508\n \n·\n \nanthropics/claude-code\n \n-\n \nGitHub,\n \naccessed\n \non\n \nJanuary\n \n5,\n \n2026,\n https://github.com/anthropics/claude-code/issues/2508 7.  Introducing  advanced  tool  use  on  the  Claude  Developer  Platform  -  Anthropic,  \naccessed\n \non\n \nJanuary\n \n5,\n \n2026,\n https://www.anthropic.com/engineering/advanced-tool-use 8.  Code  execution  tool  -  Claude  Docs,  accessed  on  January  5,  2026,  https://platform.claude.com/docs/en/agents-and-tools/tool-use/code-execution-tool 9.  ClaudeJupy:  Persistent  Python  &  Jupyter  for  Claude  AI  -  MCP  Market,  accessed  on  January  5,  2026,  https://mcpmarket.com/server/claudejupy 10.  Building  agents  with  the  Claude  Agent  SDK  -  Anthropic,  accessed  on  January  5,  \n2026,\n https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk 11.  How  to  use  Claude  Code  subagents  to  parallelize  development  -  Hacker  News,  accessed  on  January  5,  2026,  https://news.ycombinator.com/item?id=45181577 12.  v0_bash_agent.py  -  shareAI-lab/learn-claude-code  -  GitHub,  accessed  on  \nJanuary\n \n5,\n \n2026,\n https://github.com/shareAI-lab/learn-claude-code/blob/main/v0_bash_agent.py 13.  aichat:  Claude-Code/Codex-CLI  tool  for  fast  full-text  session  search,  and  \ncontinue\n \nwork\n \nwithout\n \ncompaction\n \n:\n \nr/ClaudeAI\n \n-\n \nReddit,\n \naccessed\n \non\n \nJanuary\n \n5,\n \n2026,\n https://www.reddit.com/r/ClaudeAI/comments/1pylhtq/aichat_claudecodecodexcli_tool_for_fast_fulltext/ 14.  Keeping  AI  Agents  Grounded:  Context  Engineering  Strategies  that  Prevent  \nContext\n \nRot\n \nUsing\n \nMilvus,\n \naccessed\n \non\n \nJanuary\n \n5,\n \n2026,\n https://milvus.io/blog/keeping-ai-agents-grounded-context-engineering-strategies-that-prevent-context-rot-using-milvus.md 15.  Effective  context  engineering  for  AI  agents  -  Anthropic,  accessed  on  January  5,  \n2026,\n https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents 16.  CLI  reference  -  Claude  Code  Docs,  accessed  on  January  5,  2026,  https://code.claude.com/docs/en/cli-reference 17.  Trick  to  avoid  context  rot/dumber  Claude  Code  sessions:  New  Hooks  :  r/ClaudeAI  \n-\n \nReddit,\n \naccessed\n \non\n \nJanuary\n \n5,\n \n2026,\n https://www.reddit.com/r/ClaudeAI/comments/1mib6o9/trick_to_avoid_context_rotdumber_claude_code/ \n--- PAGE 16 ---\n18.  Get  started  with  Claude  Code  hooks,  accessed  on  January  5,  2026,  https://code.claude.com/docs/en/hooks-guide 19.  SessionStart  hooks  not  working  for  new  conversations  ·  Issue  #10373  ·  \nanthropics/claude-code\n \n-\n \nGitHub,\n \naccessed\n \non\n \nJanuary\n \n5,\n \n2026,\n https://github.com/anthropics/claude-code/issues/10373 20.  Modifying  system  prompts  -  Claude  Docs,  accessed  on  January  5,  2026,  https://platform.claude.com/docs/en/agent-sdk/modifying-system-prompts 21.  Claude  Code:  Behind-the-scenes  of  the  master  agent  loop  -  PromptLayer  Blog,  \naccessed\n \non\n \nJanuary\n \n5,\n \n2026,\n https://blog.promptlayer.com/claude-code-behind-the-scenes-of-the-master-agent-loop/ 22.  Introducing  Pommel  -  an  open  source  tool  to  help  Claude  Code  find  code  without  \nburning\n \nyour\n \ncontext\n \nwindow\n \n:\n \nr/ClaudeAI\n \n-\n \nReddit,\n \naccessed\n \non\n \nJanuary\n \n5,\n \n2026,\n https://www.reddit.com/r/ClaudeAI/comments/1q0gkn8/introducing_pommel_an_open_source_tool_to_help/ 23.  Feature  Request:  Automatic  Context  Restoration  After  Autocompaction  ·  Issue  \n#6066\n \n·\n \nanthropics/claude-code\n \n-\n \nGitHub,\n \naccessed\n \non\n \nJanuary\n \n5,\n \n2026,\n https://github.com/anthropics/claude-code/issues/6066 24.  Hooks  reference  -  Claude  Code  Docs,  accessed  on  January  5,  2026,  https://code.claude.com/docs/en/hooks 25.  The  Ultimate  Claude  Code  Guide:  Every  Hidden  Trick,  Hack,  and  Power  Feature  \nYou\n \nNeed\n \nto\n \nKnow\n \n-\n \nDEV\n \nCommunity,\n \naccessed\n \non\n \nJanuary\n \n5,\n \n2026,\n https://dev.to/holasoymalva/the-ultimate-claude-code-guide-every-hidden-trick-hack-and-power-feature-you-need-to-know-2l45 26.  Claude  Code:  Best  practices  for  agentic  coding  -  Anthropic,  accessed  on  \nJanuary\n \n5,\n \n2026,\n https://www.anthropic.com/engineering/claude-code-best-practices 27.  A  few  Python  REPL  config  tricks  -  DEV  Community,  accessed  on  January  5,  2026,  https://dev.to/kenbellows/a-few-python-repl-config-tricks-3o6i 28.  Workaround  for  Claude  Code  running  python  instead  of  uv  -  Onur  Solmaz  blog,  \naccessed\n \non\n \nJanuary\n \n5,\n \n2026,\n https://solmaz.io/log/2025/07/13/claude-code-python-override/ 29.  A  Guide  to  Claude  Code  2.0  and  getting  better  at  using  coding  agents  |  sankalp's  \nblog,\n \naccessed\n \non\n \nJanuary\n \n5,\n \n2026,\n https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/ 30.  Making  Claude  Code  more  secure  and  autonomous  with  sandboxing  -  Anthropic,  \naccessed\n \non\n \nJanuary\n \n5,\n \n2026,\n https://www.anthropic.com/engineering/claude-code-sandboxing 31.  Claude  Code  on  the  web,  accessed  on  January  5,  2026,  https://code.claude.com/docs/en/claude-code-on-the-web 32.  My  setup  for  running  Claude  Code  in  YOLO  mode  without  wrecking  my  \nenvironment\n \n-\n \nReddit,\n \naccessed\n \non\n \nJanuary\n \n5,\n \n2026,\n https://www.reddit.com/r/ClaudeCode/comments/1pct552/my_setup_for_running_claude_code_in_yolo_mode/ \n--- PAGE 17 ---\n33.  Made  Claude  spawn  its  own  sub-agents  (recursive  hierarchy  with  Claude  Code  \nCLI)\n \n:\n \nr/ClaudeAI\n \n-\n \nReddit,\n \naccessed\n \non\n \nJanuary\n \n5,\n \n2026,\n https://www.reddit.com/r/ClaudeAI/comments/1pmp1lm/made_claude_spawn_its_own_subagents_recursive/ "
}